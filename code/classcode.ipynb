{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "906b49b4-79e2-4244-9787-6b9ebe648a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ruptures as rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b167b-6827-4ce3-abb0-7252a34eb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['index', 'time','deviceid','target','direction','protocol','tool','pktloss','method','zip','isp','value','topic','annonipaddr','ipaddrchanged']\n",
    "devicefulldf = pd.read_csv('/srv/data/my_shared_data_folder/internet-equity/shortened_2022.csv',names=columns)\n",
    "devicefulldf.to_csv('devicefulldf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a179f-2db2-4fe9-b6da-f070a75bd57b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_counts['date_missing_entries'] = date_counts['count'].map(lambda count: count_threshold - count if count < count_threshold else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4ce83-b653-450f-a22e-adb1885fbcc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##UPDATED VERSION\n",
    "\n",
    "class plots:\n",
    "    def __init__(self, df):\n",
    "        self.full_df = self.make_full_df(df)\n",
    "        \n",
    "    def split_time(self, df):\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        df['date'] = df['time'].dt.date\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def missing_rows_calculator(self, df):\n",
    "        count_threshold = 288\n",
    "        # Count the occurrences of each date for each deviceID and target within dataframe\n",
    "        date_counts = df.groupby(['date', 'deviceid','target']).count().reset_index()\n",
    "        \n",
    "        count_threshold = 288\n",
    "        # Count the occurrences of each date for each deviceID and target within dataframe\n",
    "        date_counts = df.groupby(['date', 'deviceid','target']).agg({\"direction\":\"count\"}).reset_index()\n",
    "        date_counts.columns = ['date', 'deviceid','target', 'count']\n",
    "        \n",
    "        # Create a new column to store the threshold comparison result\n",
    "        date_counts['date_missing_entries'] = date_counts['count'].map(lambda count: count_threshold - count if count < count_threshold else 0)\n",
    "        df = pd.merge(df, date_counts, how = \"left\", on = ['date', 'deviceid','target'])\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def make_threshold(self, df):\n",
    "        anomalydf = df.groupby(['deviceid','target']).value.agg(['mean', 'std']).reset_index()\n",
    "        anomalydf['threshold'] = anomalydf['mean'] + anomalydf['std']*2\n",
    "        anomalydf = anomalydf.drop(['mean', 'std'], axis=1)\n",
    "        df = df.merge(anomalydf, on=['deviceid','target'], how='left')\n",
    "        df['anomaly'] = (df[\"value\"] >= df[\"threshold\"])\n",
    "        \n",
    "        return df\n",
    "        \n",
    "     #Function checks for missing dates in a dataframe and add rows for those missing dates for each unique device ID present in the dataframe.\n",
    "    \n",
    "    def add_missing_dates(self, df):\n",
    "    # Fill 'date missing' column with false for the rest of the rows in the original dataframe using\n",
    "        df.loc[:, 'date missing'] = False\n",
    "    #Creates a range of dates from the minimum date to the maximum date in the 'whole date' column with a frequency of one day (daily).\n",
    "        date_range = pd.date_range(start=df['date'].min(), end=df['date'].max(), freq='D')\n",
    "    #Make an empty dictionary to keep track of missing dates for each device.\n",
    "        tracker = {}\n",
    "    #Iterates over each unique device ID in the 'deviceid' column.\n",
    "        for device in df['deviceid'].unique():\n",
    "    #Selects the unique dates for the current device using the boolean indexing and stores them in device_dates variable.\n",
    "            device_dates = df.loc[df.loc[:, \"deviceid\"] == device, \"date\"].unique()\n",
    "    #Finds the missing dates for the current device by checking which dates from date_range are not present in device_dates.\n",
    "            missing_dates = date_range[~date_range.isin(device_dates)]\n",
    "    #Stores the list of missing dates for the current device in the tracker dictionary.\n",
    "            tracker[device] = list(missing_dates)\n",
    "    #Create a list of column names from the original dataframe\n",
    "        columns = list(df.columns)\n",
    "    # Create empty dataframe with the same columns as the original dataframe\n",
    "        add_this = pd.DataFrame(columns = columns)\n",
    "    #Iterates over the tracker dictionary to access each device and its corresponding list of missing dates\n",
    "        for device, date_list in tracker.items():\n",
    "    #Gets the  length of rows in the new dataframe\n",
    "            start = len(add_this.index)\n",
    "    #Iterates over the list of missing dates for the current device.\n",
    "            for i, date in enumerate(date_list):\n",
    "    #Assigns the current device ID to the 'deviceid' column of the new row in the new dataframe\n",
    "                add_this.loc[start + i, \"deviceid\"] = device\n",
    "    #Assigns the current missing date to the 'whole date' column of the new row in the new dataframe.\n",
    "                add_this.loc[start + i, \"date\"] = date\n",
    "    #Assigns all the missing rows for the missing date\n",
    "                add_this.loc[start + i, 'date_missing_entries'] = 288\n",
    "    #Assigns new 'date missing' column to True for rows from the missing dates.\n",
    "                add_this.loc[start + i, 'date missing'] = True\n",
    "    \n",
    "    #Concatenates the original dataframe with the new dataframe we created, which contains the rows for the missing dates.\n",
    "    #The function then returns the updated DataFrame with the missing date rows added for each device.\n",
    "        #return pd.concat([df, add_this])\n",
    "        combined_df = pd.concat([df, add_this], sort=False)\n",
    "        \n",
    "        return combined_df\n",
    "    \n",
    "    def make_full_df(self, df):\n",
    "        new = self.split_time(df)\n",
    "        new = self.missing_rows_calculator(new)\n",
    "        new = self.make_threshold(new)\n",
    "        return self.add_missing_dates(new)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb7cc9-a092-4175-ad48-fbcde2890ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function checks for missing dates in a dataframe and add rows for those missing dates for each unique device ID present in the dataframe.\n",
    "def add_missing_dates(self):\n",
    "#Converts the 'whole date' column to datetime format.\n",
    "    df['whole date'] = pd.to_datetime(df['whole date'])\n",
    "#Creates a range of dates from the minimum date to the maximum date in the 'whole date' column with a frequency of one day (daily).\n",
    "    date_range = pd.date_range(start=df['whole date'].min(), end=df['whole date'].max(), freq='D')\n",
    "#Make an empty dictionary to keep track of missing dates for each device.\n",
    "    tracker = {}\n",
    "#Iterates over each unique device ID in the 'deviceid' column.\n",
    "    for device in df['deviceid'].unique():\n",
    "#Selects the unique dates for the current device using the boolean indexing and stores them in device_dates variable.\n",
    "        device_dates = df.loc[df.loc[:, \"deviceid\"] == device, \"whole date\"].unique()\n",
    "#Finds the missing dates for the current device by checking which dates from date_range are not present in device_dates.\n",
    "        missing_dates = date_range[~date_range.isin(device_dates)]\n",
    "#Stores the list of missing dates for the current device in the tracker dictionary.\n",
    "        tracker[device] = list(missing_dates)\n",
    "#Create a list of column names from the original dataframe\n",
    "    columns = list(df.columns)\n",
    "# Create empty dataframe with the same columns as the original dataframe\n",
    "    add_this = pd.DataFrame(columns = columns)\n",
    "#Iterates over the tracker dictionary to access each device and its corresponding list of missing dates\n",
    "    for device, date_list in tracker.items():\n",
    "#Gets the  length of rows in the new dataframe\n",
    "        start = len(add_this.index)\n",
    "#Iterates over the list of missing dates for the current device.\n",
    "        for i, date in enumerate(date_list):\n",
    "#Assigns the current device ID to the 'deviceid' column of the new row in the new dataframe\n",
    "            add_this.loc[start + i, \"deviceid\"] = device\n",
    "#Assigns the current missing date to the 'whole date' column of the new row in the new dataframe.\n",
    "            add_this.loc[start + i, \"whole date\"] = date\n",
    "#Assigns new 'date missing' column to True for rows from the missing dates.\n",
    "            add_this.loc[start + i, 'date missing'] = True\n",
    "# Fill 'date missing' column with false for the rest of the rows in the original dataframe using\n",
    "    df.loc[:, 'date missing'] = False\n",
    "#Concatenates the original dataframe with the new dataframe we created, which contains the rows for the missing dates.\n",
    "#The function then returns the updated DataFrame with the missing date rows added for each device.\n",
    "    #return pd.concat([df, add_this])\n",
    "    return pd.concat([df, add_this], sort=False)\n",
    "data2022_serv = add_missing_dates(data2022_serv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212342c-b07f-4aa3-8f67-a9e36c692cca",
   "metadata": {},
   "outputs": [],
   "source": [
    " def add_missing_dates(self):\n",
    "        self.df['date'] = pd.to_datetime(self.df['date'])\n",
    "        date_range = pd.date_range(start=self.df['date'].min(), end=self.df['date'].max(), freq='D')\n",
    "        tracker = {}\n",
    "        for device in self.df['deviceID'].unique():\n",
    "            device_dates = self.df.loc[self.df.loc[:, \"deviceID\"] == device, \"date\"].unique()\n",
    "            missing_dates = date_range[~date_range.isin(device_dates)]\n",
    "            tracker[device] = list(missing_dates)\n",
    "        columns = list(self.df.columns)\n",
    "        add_this = pd.DataFrame(columns = columns)\n",
    "        for device, date_list in tracker.items():\n",
    "            start = len(add_this.index)\n",
    "            for i, date in enumerate(date_list):\n",
    "                add_this.loc[start + i, \"deviceID\"] = device\n",
    "                add_this.loc[start + i, \"date\"] = date\n",
    "        self.combined_df = pd.concat([self.df, add_this])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7171b85f-3a24-44cb-8eb6-b609f34777ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = plots(devicefulldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38049a5c-77e5-4b92-8b1b-0a26638ac66a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing = test.make_full_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eee462-1778-4c06-b43f-bfb06cb0a04c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groupby = testing.groupby(['date','target','deviceID'])[['value','anomaly','date_missing_entries']].sum().reset_index()\n",
    "groupby.head(700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818988d3-9695-4db3-912e-73b0c58431b8",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''\n",
    " after missing rows function!\n",
    " \n",
    " def changept_detect(self):\n",
    "        algo = rpt.Pelt(model=\"rbf\").fit(self.fulldf[\"value\"].values)\n",
    "        result = algo.predict(pen=10)\n",
    "        self.fulldf['changepts'] = result '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59d64d-4a9c-456f-bdd1-ba8bc01e0251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a943f7-fb9e-4bd8-8e17-ef5153d47591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f57ed-3cdc-4eb6-8e4a-6775b2463057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d439f-0672-4b46-9a76-3920df390cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518077a-2891-438c-8d43-48038ff155c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7602bcc-e2d8-4006-92bb-e9b3c1caceaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70ff7f-fc7a-4bff-b46c-045f06a05d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f490ca7-0c6e-47cc-a1b4-db67db6b8892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf5fe3-fb6e-4ecb-9e22-e394f9317108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f1db1-ad4b-4191-9cc9-d04f38cef230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96600548-c00f-45c8-8c65-251d0162b545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fbdfdb-0f2d-4e3e-ad26-ee0f36307405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a67648-8ce2-4fd9-9762-f9bd461493e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c6c8b0-29ff-4a06-a5cc-c74751a2f1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdfd548-1500-4623-a79e-79e764bdddb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83852b4e-4599-4514-8823-79a788cf3184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4d7a1-0bf0-41dd-9833-5d8cf4f8a0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
